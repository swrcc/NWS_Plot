{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3211e940-cfae-4c79-ae89-2b02c3017a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_384485/3086539907.py:1: DeprecationWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas still uses PyGEOS by default. However, starting with version 0.14, the default will switch to Shapely. To force to use Shapely 2.0 now, you can either uninstall PyGEOS or set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In the next release, GeoPandas will switch to using Shapely by default, even if PyGEOS is installed. If you only have PyGEOS installed to get speed-ups, this switch should be smooth. However, if you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import folium\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from shapely.geometry import mapping\n",
    "import json\n",
    "\n",
    "# Paths to the shapefiles\n",
    "nws_shapefile_path = 'nws_data/wwa_202407010400_202407260400.shp'\n",
    "state_shapefile_path = '/nfs/home11/ugrad/2020/tr588861/SWRCC/State_Shapefiles/state/State.shp'\n",
    "county_shapefile_path = '/nfs/home11/ugrad/2020/tr588861/SWRCC/State_Shapefiles/state/Counties.shp'\n",
    "\n",
    "# Load the NWS data\n",
    "nws_data = gpd.read_file(nws_shapefile_path)\n",
    "state_boundary = gpd.read_file(state_shapefile_path)\n",
    "county_boundaries = gpd.read_file(county_shapefile_path)\n",
    "\n",
    "# Load the VTEC dictionaries from CSV files\n",
    "phenomena_df = pd.read_csv('Decoder/VTEC_PHENOMENA.csv', header=None, names=['Code', 'Description'])\n",
    "significance_df = pd.read_csv('Decoder/VTEC_SIGNIFICANCE.csv', header=None, names=['Code', 'Description'])\n",
    "colors_df = pd.read_csv('Decoder/NWS_COLORS.csv', header=None, names=['Code', 'Color'])\n",
    "\n",
    "# Convert CSV data to dictionaries\n",
    "VTEC_PHENOMENA = dict(zip(phenomena_df['Code'], phenomena_df['Description']))\n",
    "VTEC_SIGNIFICANCE = dict(zip(significance_df['Code'], significance_df['Description']))\n",
    "NWS_COLORS = dict(zip(colors_df['Code'], colors_df['Color']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c74f244-4d6d-4c55-81e8-46cac8c4a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert UTC to Eastern Time\n",
    "def convert_to_eastern(utc_time):\n",
    "    from pytz import timezone\n",
    "    eastern = timezone('US/Eastern')\n",
    "    utc = timezone('UTC')\n",
    "    utc_time = pd.to_datetime(utc_time).tz_localize('UTC')\n",
    "    eastern_time = utc_time.astimezone(eastern)\n",
    "    return eastern_time\n",
    "\n",
    "# Convert time columns to Eastern Time\n",
    "nws_data['ISSUED_ET'] = nws_data['ISSUED'].apply(convert_to_eastern)\n",
    "nws_data['EXPIRED_ET'] = nws_data['EXPIRED'].apply(convert_to_eastern)\n",
    "\n",
    "# Filter the data for new warnings\n",
    "new_warnings = nws_data[(nws_data['STATUS'] == 'NEW') & (nws_data['GTYPE'] == 'P')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71de8c4b-f7b8-4bbf-bf5f-821b4e895c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a Folium map for a specific warning type and date\n",
    "def create_warning_map(warning_type, center=[43.0, -75.0], zoom=7, date=None):\n",
    "    if date:\n",
    "        warning_data = new_warnings[(new_warnings['PHENOM'] == warning_type) & (new_warnings['ISSUED_ET'].dt.date == date)]\n",
    "    else:\n",
    "        warning_data = new_warnings[new_warnings['PHENOM'] == warning_type]\n",
    "        \n",
    "    m = folium.Map(location=center, zoom_start=zoom)\n",
    "    \n",
    "    # Add state boundary to the map\n",
    "    folium.GeoJson(\n",
    "        state_boundary,\n",
    "        style_function=lambda x: {\n",
    "            'fillColor': 'none',\n",
    "            'color': 'black',\n",
    "            'weight': 3\n",
    "        }\n",
    "    ).add_to(m)\n",
    "    \n",
    "    # Add county boundaries to the map\n",
    "    folium.GeoJson(\n",
    "        county_boundaries,\n",
    "        style_function=lambda x: {\n",
    "            'fillColor': 'none',\n",
    "            'color': 'gray',\n",
    "            'weight': 0.5\n",
    "        }\n",
    "    ).add_to(m)\n",
    "    \n",
    "    for _, row in warning_data.iterrows():\n",
    "        # Decode the PHENOM and SIG codes\n",
    "        phenom_code = row['PHENOM']\n",
    "        sig_code = row['SIG']\n",
    "        phenom_desc = VTEC_PHENOMENA.get(phenom_code, phenom_code)\n",
    "        sig_desc = VTEC_SIGNIFICANCE.get(sig_code, sig_code)\n",
    "        \n",
    "        # Get the color for the warning\n",
    "        color_key = f\"{phenom_code}.{sig_code}\"\n",
    "        color = NWS_COLORS.get(color_key, '#000000')  # Default to black if not found\n",
    "        \n",
    "        # Extract the polygon geometry\n",
    "        geom = row['geometry']\n",
    "        \n",
    "        # Convert Shapely geometry to GeoJSON\n",
    "        geo_json = gpd.GeoSeries([geom]).__geo_interface__\n",
    "        \n",
    "        # Add the polygon to the map\n",
    "        folium.GeoJson(\n",
    "            geo_json,\n",
    "            style_function=lambda x, color=color: {\n",
    "                'fillColor': color,\n",
    "                'color': color,\n",
    "                'weight': 2,\n",
    "                'fillOpacity': 0.4\n",
    "            },\n",
    "            tooltip=f\"{phenom_desc} {sig_desc}\"\n",
    "        ).add_to(m)\n",
    "    \n",
    "    return m\n",
    "\n",
    "# Create the combined map function with optional date filtering\n",
    "def create_combined_map(center=[43.0, -75.0], zoom=7, date=None):\n",
    "    combined_map = folium.Map(location=center, zoom_start=zoom)\n",
    "    \n",
    "    # Add state boundary to the map\n",
    "    folium.GeoJson(\n",
    "        state_boundary,\n",
    "        style_function=lambda x: {\n",
    "            'fillColor': 'none',\n",
    "            'color': 'black',\n",
    "            'weight': 3\n",
    "        }\n",
    "    ).add_to(combined_map)\n",
    "    \n",
    "    # Add county boundaries to the map\n",
    "    folium.GeoJson(\n",
    "        county_boundaries,\n",
    "        style_function=lambda x: {\n",
    "            'fillColor': 'none',\n",
    "            'color': 'gray',\n",
    "            'weight': 0.5\n",
    "        }\n",
    "    ).add_to(combined_map)\n",
    "    \n",
    "    for warning_type in ['SV', 'TO', 'FF']:\n",
    "        if date:\n",
    "            warning_data = new_warnings[(new_warnings['PHENOM'] == warning_type) & (new_warnings['ISSUED_ET'].dt.date == date)]\n",
    "        else:\n",
    "            warning_data = new_warnings[new_warnings['PHENOM'] == warning_type]\n",
    "        \n",
    "        for _, row in warning_data.iterrows():\n",
    "            # Decode the PHENOM and SIG codes\n",
    "            phenom_code = row['PHENOM']\n",
    "            sig_code = row['SIG']\n",
    "            phenom_desc = VTEC_PHENOMENA.get(phenom_code, phenom_code)\n",
    "            sig_desc = VTEC_SIGNIFICANCE.get(sig_code, sig_code)\n",
    "            \n",
    "            # Get the color for the warning\n",
    "            color_key = f\"{phenom_code}.{sig_code}\"\n",
    "            color = NWS_COLORS.get(color_key, '#000000')  # Default to black if not found\n",
    "            \n",
    "            # Extract the polygon geometry\n",
    "            geom = row['geometry']\n",
    "            \n",
    "            # Convert Shapely geometry to GeoJSON\n",
    "            geo_json = gpd.GeoSeries([geom]).__geo_interface__\n",
    "            \n",
    "            # Add the polygon to the map\n",
    "            folium.GeoJson(\n",
    "                geo_json,\n",
    "                style_function=lambda x, color=color: {\n",
    "                    'fillColor': color,\n",
    "                    'color': color,\n",
    "                    'weight': 2,\n",
    "                    'fillOpacity': 0.4\n",
    "                },\n",
    "                tooltip=f\"{phenom_desc} {sig_desc}\"\n",
    "            ).add_to(combined_map)\n",
    "    \n",
    "    return combined_map\n",
    "\n",
    "# Create maps for each warning type\n",
    "severe_thunderstorm_map = create_warning_map('SV')\n",
    "tornado_map = create_warning_map('TO')\n",
    "flash_flood_map = create_warning_map('FF')\n",
    "\n",
    "# Create the Output_Maps directory if it doesn't exist\n",
    "output_dir = 'Output_Maps'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the maps to the Output_Maps directory\n",
    "severe_thunderstorm_map.save(os.path.join(output_dir, 'severe_thunderstorm_map.html'))\n",
    "tornado_map.save(os.path.join(output_dir, 'tornado_map.html'))\n",
    "flash_flood_map.save(os.path.join(output_dir, 'flash_flood_map.html'))\n",
    "\n",
    "# Create the combined map\n",
    "combined_map = create_combined_map()\n",
    "\n",
    "# Save the combined map to the Output_Maps directory\n",
    "combined_map.save(os.path.join(output_dir, 'combined_warning_map.html'))\n",
    "\n",
    "# Generate maps for a specific date if needed\n",
    "specific_date = datetime(2024, 7, 10).date()\n",
    "\n",
    "severe_thunderstorm_map_date = create_warning_map('SV', date=specific_date)\n",
    "tornado_map_date = create_warning_map('TO', date=specific_date)\n",
    "flash_flood_map_date = create_warning_map('FF', date=specific_date)\n",
    "combined_map_date = create_combined_map(date=specific_date)\n",
    "\n",
    "# Save the specific date maps to the Output_Maps directory\n",
    "severe_thunderstorm_map_date.save(os.path.join(output_dir, f'severe_thunderstorm_map_{specific_date}.html'))\n",
    "tornado_map_date.save(os.path.join(output_dir, f'tornado_map_{specific_date}.html'))\n",
    "flash_flood_map_date.save(os.path.join(output_dir, f'flash_flood_map_{specific_date}.html'))\n",
    "combined_map_date.save(os.path.join(output_dir, f'combined_warning_map_{specific_date}.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d3ccd7c-053c-4813-8a34-3457f152505e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary and maps have been generated and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_384485/2705027570.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unique_data['PHENOM'] = unique_data['PHENOM'].map(VTEC_PHENOMENA)\n",
      "/tmp/ipykernel_384485/2705027570.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unique_data['SIG'] = unique_data['SIG'].map(VTEC_SIGNIFICANCE)\n",
      "/tmp/ipykernel_384485/2705027570.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unique_data['ALERT_TYPE'] = unique_data['PHENOM'] + ' ' + unique_data['SIG']\n"
     ]
    }
   ],
   "source": [
    "# Reproject to UTM zone 18N (EPSG:32618)\n",
    "nws_data = nws_data.to_crs(epsg=32618)\n",
    "state_boundary = state_boundary.to_crs(epsg=32618)\n",
    "\n",
    "# Spatial join to find the intersection\n",
    "intersection = gpd.overlay(nws_data, state_boundary, how='intersection')\n",
    "\n",
    "# Filter by minimum area within NY (adjust threshold as needed)\n",
    "min_area_threshold = 1e6  # 1,000,000 square meters (1 square kilometer)\n",
    "intersection['area'] = intersection.geometry.area\n",
    "filtered_intersection = intersection[intersection['area'] >= min_area_threshold]\n",
    "\n",
    "# Convert to DataFrame for further processing\n",
    "filtered_data = pd.DataFrame(filtered_intersection.drop(columns='geometry'))\n",
    "\n",
    "# Convert UTC to Eastern Time\n",
    "filtered_data['ISSUED'] = pd.to_datetime(filtered_data['ISSUED'], format='%Y%m%d%H%M')\n",
    "filtered_data['ISSUED_ET'] = filtered_data['ISSUED'].dt.tz_localize('UTC').dt.tz_convert('US/Eastern')\n",
    "\n",
    "# Extract the date part for easier filtering\n",
    "filtered_data['ISSUED_DATE_ET'] = filtered_data['ISSUED_ET'].dt.date\n",
    "\n",
    "# Remove duplicates to keep only the 'NEW' status and 'P' type\n",
    "unique_data = filtered_data[(filtered_data['STATUS'] == 'NEW') & (filtered_data['GTYPE'] == 'P')]\n",
    "\n",
    "# Translate PHENOM and SIG columns\n",
    "unique_data['PHENOM'] = unique_data['PHENOM'].map(VTEC_PHENOMENA)\n",
    "unique_data['SIG'] = unique_data['SIG'].map(VTEC_SIGNIFICANCE)\n",
    "\n",
    "# Create a new column for the combined alert type\n",
    "unique_data['ALERT_TYPE'] = unique_data['PHENOM'] + ' ' + unique_data['SIG']\n",
    "\n",
    "# Deduplicate based on the maximum area for each alert type and time\n",
    "max_area_alerts = unique_data.loc[\n",
    "    unique_data.groupby(['ISSUED_ET', 'ALERT_TYPE'])['area'].idxmax()\n",
    "]\n",
    "\n",
    "# Group by date and alert type and count occurrences\n",
    "summary = max_area_alerts.groupby(['ISSUED_DATE_ET', 'ALERT_TYPE']).size().reset_index(name='Count')\n",
    "\n",
    "# Save the summary to a CSV file in the Output_Maps directory\n",
    "summary_csv_path = os.path.join(output_dir, 'nws_warning_summary.csv')\n",
    "summary.to_csv(summary_csv_path, index=False)\n",
    "\n",
    "print(\"Summary and maps have been generated and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b747a9-427e-4130-9312-fd80c16fb479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 August 2023 Environment",
   "language": "python",
   "name": "aug23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
